import streamlit as st
import pandas as pd
import datetime
import io
import json
import xlsxwriter
import numpy as np
import plotly.graph_objects as go
from meteostat import Point, Hourly
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# ------------------------------------------------------
# 0. ì‹œìŠ¤í…œ ì„¤ì •
# ------------------------------------------------------
st.set_page_config(
    page_title="Forensic AI V21.3 (Final Fix)", 
    layout="wide", 
    page_icon="ğŸ•µï¸â€â™‚ï¸",
    initial_sidebar_state="expanded"
)

# ------------------------------------------------------
# 1. AI ë‘ë‡Œ
# ------------------------------------------------------
class AICommanderGemini:
    def __init__(self, api_key, model_name):
        genai.configure(api_key=api_key)
        
        self.safety_settings = {
            HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
            HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
        }
        
        self.model_name = model_name
        self.model = genai.GenerativeModel(
            model_name=self.model_name, 
            safety_settings=self.safety_settings
        )
        
    def parse_command(self, user_text):
        system_prompt = """
        You are a Forensic AI Profiler. Output ONLY raw JSON. Do not use Markdown blocks.
        
        JSON Structure:
        {
            "simulation": {
                "species": "String (Latin name or null)",
                "stage": "String (stage key or null)",
                "maggot_heat": "Float (default 0)",
                "event": {
                    "active": "Boolean",
                    "temp_increase": "Float",
                    "duration": "Integer",
                    "end_hours_ago": "Integer"
                }
            },
            "profiling": {
                "homicide_prob": "Integer (0-100)",
                "suicide_prob": "Integer (0-100)",
                "accident_prob": "Integer (0-100)",
                "reasoning": "String (Short explanation in Korean)"
            }
        }
        """
        try:
            response = self.model.generate_content(f"{system_prompt}\n\nUser Scenario: {user_text}")
            clean_text = response.text.replace("```json", "").replace("```", "").strip()
            return json.loads(clean_text)
        except Exception as e:
            st.error(f"âš ï¸ ëª¨ë¸({self.model_name}) ì˜¤ë¥˜: {e}")
            return None

# ------------------------------------------------------
# 2. ê³„ì‚° ì—”ì§„ (ì˜¤ë¥˜ ìˆ˜ì •ë¨)
# ------------------------------------------------------
class MasterPMICalculatorV21:
    def __init__(self):
        self.insect_db = {
            "Lucilia sericata (Korea - Busan)": {"Type": "í•œêµ­í˜•", "LDT": 4.5, "UDT": 35.0, "stages": {"egg": 35, "instar_1": 150, "instar_2": 350, "instar_3_feed": 550, "instar_3_wander": 702, "pupa": 4901}},
            "Chrysomya megacephala (ëŒ€ë™íŒŒë¦¬)": {"Type": "ê³ ì˜¨ì„±", "LDT": 10.0, "UDT": 40.0, "stages": {"egg": 15, "instar_1": 300, "instar_2": 700, "instar_3_feed": 1300, "instar_3_wander": 2200, "pupa": 3800}},
            "Lucilia sericata (Global/Avg)": {"Type": "ì¼ë°˜", "LDT": 9.0, "UDT": 35.0, "stages": {"egg": 20, "instar_1": 300, "instar_2": 800, "instar_3_feed": 1400, "instar_3_wander": 2400, "pupa": 4000}}
        }

    def calculate(self, species_name, stage, df_weather, correction=1.0, max_maggot_heat=0.0, event_params=None):
        data = self.insect_db[species_name]
        ldt, udt, stages = data['LDT'], data['UDT'], data['stages']
        target_adh = stages[stage]
        accumulated_adh, adh_history = 0.0, []
        discovery_time = df_weather['Time'].max()

        for idx, row in df_weather.iterrows():
            base_temp = row['Temp'] # ì›ë˜ ê¸°ì˜¨ ì €ì¥
            current_temp = base_temp
            
            # ë§ˆê³³ ë°œì—´
            if max_maggot_heat > 0 and accumulated_adh > stages['instar_1']: 
                current_temp += max_maggot_heat
            
            # ì´ë²¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜
            is_event = False
            if event_params and event_params['active']:
                h_diff = (discovery_time - row['Time']).total_seconds() / 3600
                if event_params['end_hours_ago'] <= h_diff <= (event_params['end_hours_ago'] + event_params['duration']):
                    current_temp += event_params['temp_increase']
                    is_event = True

            eff_heat = (current_temp - ldt) if ldt < current_temp < udt else 0
            accumulated_adh += eff_heat
            
            # [ìˆ˜ì •] ì—¬ê¸°ì— Base_Tempë¥¼ ê¼­ ë„£ì–´ì¤˜ì•¼ ê·¸ë˜í”„ê°€ ê·¸ë ¤ì§‘ë‹ˆë‹¤!
            adh_history.append({
                "Time": row['Time'], 
                "Base_Temp": base_temp,      # <-- ì´ ë¶€ë¶„ì´ í•µì‹¬! (ì›ë˜ ê¸°ì˜¨)
                "Final_Temp": current_temp,  # (ë³´ì •ëœ ê¸°ì˜¨)
                "Event": is_event
            })
            
            if accumulated_adh >= target_adh: return row['Time'], pd.DataFrame(adh_history)
        return None, pd.DataFrame(adh_history)

# ------------------------------------------------------
# 3. UI ë° ì œì–´
# ------------------------------------------------------
st.title("ğŸ•µï¸â€â™‚ï¸ Forensic AI Profiler V21.3")
st.markdown("##### âš™ï¸ ëª¨ë¸ êµì²´í˜• ì‹œë®¬ë ˆì´í„° (Graph Fixed)")

if 'use_event' not in st.session_state: st.session_state.update({'sp_idx': 0, 'st_idx': 3, 'max_heat': 5.0, 'use_event': False, 'ev_temp': 15.0, 'ev_dur': 2, 'ev_end': 6, 'ai_log': "ì¤€ë¹„ ì™„ë£Œ"})

with st.sidebar:
    st.header("ğŸ§  AI ëª¨ë¸ ì„ íƒ")
    
    model_options = [
        "models/gemini-flash-latest",    
        "models/gemini-pro-latest",      
        "models/gemini-2.0-flash-exp",   
        "models/gemini-2.5-flash-lite-preview" 
    ]
    selected_model = st.selectbox("ì‚¬ìš©í•  AI ëª¨ë¸:", model_options, index=0)
    st.info(f"ì„ íƒë¨: {selected_model}")

    st.divider()
    st.header("ğŸ™ï¸ ìˆ˜ì‚¬ ì‹œë‚˜ë¦¬ì˜¤")
    
    if "GOOGLE_API_KEY" in st.secrets:
        api_key = st.secrets["GOOGLE_API_KEY"]
        ai_available = True
    else:
        api_key = None
        ai_available = False
        st.error("API Key ì—†ìŒ")

    user_voice = st.text_area("ìƒí™© ë¬˜ì‚¬", placeholder="ì˜ˆ: ëŒ€ë™íŒŒë¦¬ 1ë ¹ ë°œê²¬. ì‹œì‹ ì€ ì˜·ì´ ë²—ê²¨ì§„ ì±„ ë¤ë¶ˆ ì†ì— ì€íë˜ì–´ ìˆì—ˆê³ ...", height=150)
    
    if st.button("ğŸ” ë¶„ì„ ì‹¤í–‰", disabled=not ai_available):
        if user_voice:
            agent = AICommanderGemini(api_key, selected_model)
            with st.spinner(f"AI({selected_model})ê°€ í”„ë¡œíŒŒì¼ë§ ì¤‘ì…ë‹ˆë‹¤..."):
                result = agent.parse_command(user_voice)
            
            if result:
                prof = result.get("profiling", {})
                sim = result.get("simulation", {})
                
                st.divider()
                st.subheader("ğŸ“Š ë¶„ì„ ê²°ê³¼")
                h, s, a = prof.get("homicide_prob", 0), prof.get("suicide_prob", 0), prof.get("accident_prob", 0)
                
                c1, c2, c3 = st.columns(3)
                c1.metric("íƒ€ì‚´", f"{h}%")
                c2.metric("ìì‚´", f"{s}%")
                c3.metric("ì‚¬ê³ ì‚¬", f"{a}%")
                st.progress(h)
                st.info(f"ğŸ’¡ **AI íŒë‹¨:** {prof.get('reasoning')}")

                st.session_state['ai_log'] = "âœ… ì„¤ì • ì ìš© ì™„ë£Œ"
                if sim.get("species"):
                    for i, k in enumerate(MasterPMICalculatorV21().insect_db.keys()):
                        if sim["species"].split()[0] in k:
                            st.session_state['sp_idx'] = i; break
                if sim.get("stage"):
                    stages = ["egg", "instar_1", "instar_2", "instar_3_feed", "instar_3_wander", "pupa"]
                    if sim["stage"] in stages: st.session_state['st_idx'] = stages.index(sim["stage"])
                if sim.get("event") and sim["event"]["active"]:
                    st.session_state['use_event'] = True
                    st.session_state['ev_temp'] = sim["event"]["temp_increase"]
                    st.session_state['ev_dur'] = sim["event"]["duration"]
                    st.session_state['ev_end'] = sim["event"]["end_hours_ago"]
                st.rerun()

cal = MasterPMICalculatorV21()
c1, c2 = st.columns(2)
with c1:
    st.subheader("1. ê³¤ì¶© ì„¤ì •")
    sp = st.selectbox("íŒŒë¦¬ ì¢…", list(cal.insect_db.keys()), index=st.session_state['sp_idx'])
    stg = st.selectbox("ì„±ì¥ ë‹¨ê³„", list(cal.insect_db[sp]['stages'].keys()), index=st.session_state['st_idx'])
    max_h = st.slider("ë§ˆê³³ ë§¤ìŠ¤ ë°œì—´ (Â°C)", 0.0, 20.0, st.session_state['max_heat'])

with c2:
    st.subheader("2. ì´ë²¤íŠ¸ ì„¤ì •")
    use_ev = st.checkbox("ì´ë²¤íŠ¸ ì ìš©", value=st.session_state['use_event'])
    e_temp = st.number_input("ì˜¨ë„ ë³€í™”", value=st.session_state['ev_temp'], disabled=not use_ev)
    e_dur = st.number_input("ì§€ì† ì‹œê°„", value=st.session_state['ev_dur'], disabled=not use_ev)
    e_end = st.number_input("ì¢…ë£Œ ì‹œì  (ë°œê²¬ ì „)", value=st.session_state['ev_end'], disabled=not use_ev)

if st.button("ğŸ“¡ ê³„ì‚° ì‹œì‘"):
    pt = Point(35.1796, 129.0756)
    w_data = Hourly(pt, datetime.datetime.now()-datetime.timedelta(days=30), datetime.datetime.now()).fetch()
    if not w_data.empty:
        w_df = w_data.reset_index().rename(columns={'time':'Time','temp':'Temp'}).sort_values('Time', ascending=False).interpolate()
        est, log = cal.calculate(sp, stg, w_df, max_maggot_heat=max_h, event_params={"active": use_ev, "temp_increase": e_temp, "duration": st.session_state['ev_dur'], "end_hours_ago": st.session_state['ev_end']})
        
        if est:
            st.success(f"ğŸ ì¶”ì • ì‚¬ë§ ì‹œê°: {est}")
            
            # [ê·¸ë˜í”„ ê·¸ë¦¬ê¸°]
            fig = go.Figure()
            # ë¹¨ê°„ì„ : ìµœì¢… ê¸°ì˜¨ (ì´ë²¤íŠ¸ í¬í•¨)
            fig.add_trace(go.Scatter(x=log['Time'], y=log['Final_Temp'], name='ì‹œì‹  ì²´ê° ì˜¨ë„', line=dict(color='red')))
            # íšŒìƒ‰ì„ : ì›ë˜ ê¸°ìƒì²­ ê¸°ì˜¨ (ë¹„êµìš©)
            fig.add_trace(go.Scatter(x=log['Time'], y=log['Base_Temp'], name='ê¸°ìƒì²­ ê¸°ì˜¨', line=dict(color='gray', dash='dot')))
            
            if use_ev:
                e_rows = log[log['Event']==True]
                if not e_rows.empty: 
                    fig.add_vrect(x0=e_rows['Time'].min(), x1=e_rows['Time'].max(), fillcolor="blue", opacity=0.1, annotation_text="Event")
            
            st.plotly_chart(fig, use_container_width=True)
        else: 
            st.error("ê³„ì‚° ì‹¤íŒ¨")